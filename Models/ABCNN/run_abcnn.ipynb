{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_abcnn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOVCGYLElDpbB8uEJmmiyfS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"i3N9gGzoeA1j"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqDrwK0heZuk"},"source":["%cd /content/drive/My Drive/Sentence_pair_modeling/Models/ABCNN/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"meKfSIGTAvWx"},"source":["! pip3 install hanziconv\n","! pip3 install jsonlines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo-3q5LieDvW"},"source":["# **LCQMC**"]},{"cell_type":"markdown","metadata":{"id":"GF_zegUUPd51"},"source":["## LCQMC train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"GWFoDZoflqQm"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"_0VyxRm30pY_"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from util import Metric\n","import os\n","\n","lcqmc_path = \"/content/drive/My Drive/Sentence_pair_modeling/LCQMC/\"\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_word_vocab.txt\")\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ssoicj3i0tqD"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"lqiRmRcRJU_f"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FOduME40lwZj"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"gVHkpPxAQOUM"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3z7EgOCNr5P"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"f6k2CnzrNsJG"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mx6YQa37eDp6"},"source":["## LCQMC infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"UtBYQMbVX-c9"},"source":["from run_ABCNN_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/ABCNN_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(bq_path, \"output/Infer_LCQMC\") # where to save the infer result\n","test_prediction_name = 'ABCNN_test_prediction.csv' # the infer result name\n"," \n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jS5NgyYKeDj5"},"source":["# **XiAn**"]},{"cell_type":"markdown","metadata":{"id":"Av-WTwFzeDY6"},"source":["## XiAn train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"dFVs-_d6l0AR"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"i1bMSd_VhoUu"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","xian_path = \"/content/drive/My Drive/Sentence_pair_modeling/XiAn_STS/\"\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/ABCNN_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DxpZEPcbYrtm"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"p2OQoTy2YvO-"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(xian_path, \"output/ABCNN_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pToD5-gBl3fQ"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"nXmJMgm_c3Za"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/ABCNN_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aFf2G2S4dcOm"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"ncrzbR9XdcgX"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/ABCNN_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"627J5Kd6f9Mu"},"source":["## XiAn infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"q18QArTfeDWL"},"source":["from run_ABCNN_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_XiAn\") # where to save the infer result\n","test_prediction_name = 'ABCNN_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jt-WlKAtgqbs"},"source":["# **BQ**"]},{"cell_type":"markdown","metadata":{"id":"YzODBNpygqWf"},"source":["## BQ train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"HOAe0629l6df"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"l7P7WqLsj3gD"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","bq_path = \"/content/drive/My Drive/Sentence_pair_modeling/BQ Corpus/\"\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/ABCNN_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LSUqiV4eh6rp"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"OtHRyZmUh7AZ"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(bq_path, \"output/ABCNN_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AeZgFI1AnHxV"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"TjkRfBWbnINE"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/ABCNN_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgNQZlk2l-Gi"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"9UY6CAjQgp-B"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/ABCNN_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"woHoSXnvgp5m"},"source":["## BQ infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"mKOe7B82gpz6"},"source":["from run_ABCNN_model import model_load_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/ABCNN_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_BQ\") # where to save the infer result\n","test_prediction_name = 'ABCNN_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi2wCsxGgpnj"},"source":["# **OCNLI**"]},{"cell_type":"markdown","metadata":{"id":"j-YT6ODHlQdp"},"source":["### OCNLI train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"S3568B4ulQaW"},"source":["#### word embedding"]},{"cell_type":"code","metadata":{"id":"tZ6SSsfLlQX0"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6GuOgH7ElQVS"},"source":["#### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"D5gm1D7blQSo"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"htw3VLKmlQP1"},"source":["#### char embedding"]},{"cell_type":"code","metadata":{"id":"whVy7jK6liow"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1gvH4hyljPH"},"source":["#### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"J5wo35pEmreb"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-insXZNAJCZ"},"source":["# **CMNLI**"]},{"cell_type":"markdown","metadata":{"id":"HFJXFGGXAJVh"},"source":["## CMNLI train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"ufGBjEdkAJ0S"},"source":["### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"wpeCJ2EqAJt9"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","cmnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/CMNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BOZOw2tKAJSq"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"9k_016JlAI_6"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JPm1b891AZ_j"},"source":["### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"mFELEJ-WAcpu"},"source":["from run_ABCNN_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/ABCNN_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]}]}