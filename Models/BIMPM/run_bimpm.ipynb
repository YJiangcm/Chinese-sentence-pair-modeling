{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"run_bimpm.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMF0H9Xrz8dT+lBOMeQItMM"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"i3N9gGzoeA1j"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqDrwK0heZuk"},"source":["%cd /content/drive/My Drive/Sentence_pair_modeling/Models/BIMPM/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"meKfSIGTAvWx"},"source":["! pip3 install hanziconv\n","! pip3 install jsonlines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo-3q5LieDvW"},"source":["# **LCQMC**"]},{"cell_type":"markdown","metadata":{"id":"GF_zegUUPd51"},"source":["## LCQMC train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"KLHlCcXAmKMi"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"BItBZKkWmKCX"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","lcqmc_path = \"/content/drive/My Drive/Sentence_pair_modeling/LCQMC/\"\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_word_vocab.txt\")\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_word_rand/\") \n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80geb58Jr--N"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"VF2FM9yFr900"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yIZzMLQcsa0H"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"RvVIvMp4saks"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6w56PmLymJoS"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"gVHkpPxAQOUM"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mx6YQa37eDp6"},"source":["## LCQMC infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"UtBYQMbVX-c9"},"source":["from run_BIMPM_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BIMPM_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(bq_path, \"output/Infer_LCQMC\") # where to save the infer result\n","test_prediction_name = 'BIMPM_test_prediction.csv' # the infer result name\n"," \n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jS5NgyYKeDj5"},"source":["# **XiAn**"]},{"cell_type":"markdown","metadata":{"id":"Av-WTwFzeDY6"},"source":["# XiAn train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"WrMDJhMSmmlg"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"NN0h6Vysmmcu"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","xian_path = \"/content/drive/My Drive/Sentence_pair_modeling/XiAn_STS/\"\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BIMPM_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SH-FDQoTu5Jv"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"F5lNfwVlu5DZ"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(xian_path, \"output/BIMPM_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1opmg7pcu471"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"gOFDgJ8Bu4uH"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BIMPM_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_PZyBtlPmmTU"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"nXmJMgm_c3Za"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BIMPM_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"627J5Kd6f9Mu"},"source":["## XiAn infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"q18QArTfeDWL"},"source":["from run_BIMPM_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_XiAn\") # where to save the infer result\n","test_prediction_name = 'BIMPM_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jt-WlKAtgqbs"},"source":["# **BQ**"]},{"cell_type":"markdown","metadata":{"id":"YzODBNpygqWf"},"source":["## BQ train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"EOFJoLzmm6_h"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"sRObsHNNm6t4"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","bq_path = \"/content/drive/My Drive/Sentence_pair_modeling/BQ Corpus/\"\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BIMPM_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7OX23bF2vSVr"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"zmG1boF2vSRR"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(bq_path, \"output/BIMPM_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oiWdtPavSOT"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"LtOI6_pFvSKU"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BIMPM_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7dGTeOiQm5Ts"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"9UY6CAjQgp-B"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BIMPM_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"woHoSXnvgp5m"},"source":["## BQ infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"mKOe7B82gpz6"},"source":["from run_BIMPM_model import model_load_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BIMPM_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_BQ\") # where to save the infer result\n","test_prediction_name = 'BIMPM_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi2wCsxGgpnj"},"source":["# **OCNLI**"]},{"cell_type":"markdown","metadata":{"id":"uxeX5mjkV9-x"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"5WNUlVjqV971"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S7MldzrzV-il"},"source":["### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"iCNp11lrV-nb"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV4thrKV-tQ"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"UmTnZ_k4V-zA"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PbyXm9PJV-75"},"source":["### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"FMyc_YFuV-14"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cV-ySICvV-v_"},"source":["# **CMNLI**"]},{"cell_type":"markdown","metadata":{"id":"2_bWCTK7V-qi"},"source":["### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"rVPYRZL3V-k0"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","cmnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/CMNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zgJQFTxWV-f-"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"To9cdcV6WaH6"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yO3daSpRWagv"},"source":["### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"Txw29-bwWd5Y"},"source":["from run_BIMPM_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BIMPM_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]}]}