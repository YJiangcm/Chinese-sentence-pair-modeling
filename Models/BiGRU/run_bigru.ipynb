{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_bigru.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyO25jk9yZ0rG/n7uid/Oc2a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"i3N9gGzoeA1j"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqDrwK0heZuk"},"source":["%cd /content/drive/My Drive/Sentence_pair_modeling/Models/BiGRU/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"meKfSIGTAvWx"},"source":["! pip3 install hanziconv\n","! pip3 install jsonlines"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo-3q5LieDvW"},"source":["# **LCQMC**"]},{"cell_type":"markdown","metadata":{"id":"GF_zegUUPd51"},"source":["## LCQMC train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"xb28bFA3pGJb"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"Y-WZWm7DpF93"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","lcqmc_path = \"/content/drive/My Drive/Sentence_pair_modeling/LCQMC/\"\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_word_vocab.txt\")\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yd4_I72M3yaH"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"3-p8qVDJ3yWv"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpxM4ika3yT_"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"H2z0g9jV3yRC"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nuL3vSrQpFy-"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"gVHkpPxAQOUM"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mx6YQa37eDp6"},"source":["## LCQMC infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"UtBYQMbVX-c9"},"source":["from run_SiaGRU_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(lcqmc_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(lcqmc_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(lcqmc_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BiGRU_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(bq_path, \"output/Infer_LCQMC\") # where to save the infer result\n","test_prediction_name = 'BiGRU_test_prediction.csv' # the infer result name\n"," \n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jS5NgyYKeDj5"},"source":["# **XiAn**"]},{"cell_type":"markdown","metadata":{"id":"Av-WTwFzeDY6"},"source":["## XiAn train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"a1H6XZQBpX0P"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"7ADpYgAfpXqf"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","xian_path = \"/content/drive/My Drive/Sentence_pair_modeling/XiAn_STS/\"\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BiGRU_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZG2z_nA4zjC"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"-xx5ZaW24zee"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","target_dir = os.path.join(xian_path, \"output/BiGRU_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xKHM3Fi14zbW"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"t0EugOUk4zYO"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(xian_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BiGRU_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UAPsWK6FpXfb"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"nXmJMgm_c3Za"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(xian_path, \"output/BiGRU_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"627J5Kd6f9Mu"},"source":["## XiAn infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"q18QArTfeDWL"},"source":["from run_BiGRU_model import model_load_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(xian_path, \"data/train.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(xian_path, \"data/dev.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(xian_path, \"data/test.tsv\"),sep='\\t',header=None, names=['s1','s2','label'])\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_XiAn\") # where to save the infer result\n","test_prediction_name = 'BiGRU_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jt-WlKAtgqbs"},"source":["# **BQ**"]},{"cell_type":"markdown","metadata":{"id":"YzODBNpygqWf"},"source":["## BQ train-validate-test"]},{"cell_type":"markdown","metadata":{"id":"g0sf-uCwplMp"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"3e5TLNwopk__"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","bq_path = \"/content/drive/My Drive/Sentence_pair_modeling/BQ Corpus/\"\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_word_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BiGRU_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXHyuXlc5x58"},"source":["### word embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"F-UWqoma5x2k"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(bq_path, \"output/BiGRU_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLZvVjbG5x0A"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"UOLvFWFO5xw3"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","vocab_file = os.path.join(bq_path, \"data/rand_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BiGRU_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-JtRCR2pk1U"},"source":["### char embedding-pretrained"]},{"cell_type":"code","metadata":{"id":"9UY6CAjQgp-B"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(bq_path, \"output/BiGRU_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             num_labels=2,\n","             max_length=64,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"woHoSXnvgp5m"},"source":["## BQ infer by other pretrained models"]},{"cell_type":"code","metadata":{"id":"mKOe7B82gpz6"},"source":["from run_BiGRU_model import model_load_test\n","import pandas as pd\n","from utils import Metric, json2df\n","import os\n","\n","train_df = json2df(os.path.join(bq_path, \"data/train.json\"))\n","dev_df = json2df(os.path.join(bq_path, \"data/dev.json\"))\n","test_df = json2df(os.path.join(bq_path, \"data/test.json\"))\n","data = pd.concat([train_df,dev_df,test_df]).reset_index(drop=True)\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(lcqmc_path, \"output/BiGRU_char_pre/best.pth.tar\") # load pretrained model\n","test_prediction_dir = os.path.join(lcqmc_path, \"output/Infer_BQ\") # where to save the infer result\n","test_prediction_name = 'BiGRU_test_prediction.csv' # the infer result name\n","\n","model_load_test(test_df = data,\n","                vocab_file = vocab_file,\n","                embeddings_file = embeddings_file,\n","                pretrained_file = target_dir,\n","                test_prediction_dir = test_prediction_dir,\n","                test_prediction_name = test_prediction_name,\n","                mode = 'char',\n","                max_length=64,\n","                gpu_index=0, \n","                batch_size=128)\n","\n","test_result = pd.read_csv(os.path.join(test_prediction_dir, test_prediction_name))\n","Metric(data.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi2wCsxGgpnj"},"source":["# **OCNLI**"]},{"cell_type":"markdown","metadata":{"id":"OxdEoYSrfTzQ"},"source":["### word embedding"]},{"cell_type":"code","metadata":{"id":"adZeRd9BfTda"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_word_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iEyGSNsFepFe"},"source":["### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"uf4Ky_MSepNP"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","ocnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/OCNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/word_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-CM64iRepUz"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"uX5sMWR3epdF"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8YPOK8q3eplS"},"source":["### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"B8eRuLwgeps9"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train.csv\"),header=None, names=['s1','s2','label','genre'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label','genre'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label','genre'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=False,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HilTFF0Oep0v"},"source":["# **CMNLI**"]},{"cell_type":"markdown","metadata":{"id":"MVzSwLKKep8l"},"source":["### word embedding pretrained"]},{"cell_type":"code","metadata":{"id":"ymaaDVLReqEq"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","cmnli_path = \"/content/drive/My Drive/Sentence_pair_modeling/CMNLI/\"\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_word_vocab.txt\")\n","embeddings_file = os.path.join(lcqmc_path, \"data/word_vec_300.iter5\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_word_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'word',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=32,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yHDChgzzeqMi"},"source":["### char embedding"]},{"cell_type":"code","metadata":{"id":"6bbBwKJUeqUv"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","vocab_file = os.path.join(ocnli_path, \"data/char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_char_rand/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = None,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.001,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJZIG3Eueqar"},"source":["### char embedding pretrained"]},{"cell_type":"code","metadata":{"id":"fCUiaEk-eqSC"},"source":["from run_BiGRU_model import model_train_validate_test\n","import pandas as pd\n","from utils import Metric\n","import os\n","\n","train_df = pd.read_csv(os.path.join(ocnli_path, \"data/train1.csv\"),header=None, names=['s1','s2','label'])\n","dev_df = pd.read_csv(os.path.join(ocnli_path, \"data/dev.csv\"),header=None, names=['s1','s2','label'])\n","test_df = pd.read_csv(os.path.join(ocnli_path, \"data/test.csv\"),header=None, names=['s1','s2','label'])\n","\n","embeddings_file = os.path.join(lcqmc_path, \"data/token_vec_300.bin\")\n","vocab_file = os.path.join(lcqmc_path, \"data/pre_char_vocab.txt\")\n","\n","target_dir = os.path.join(ocnli_path, \"output/BiGRU_char_pre/\")\n","\n","model_train_validate_test(train_df = train_df,\n","             dev_df = dev_df,\n","             test_df = test_df,\n","             embeddings_file = embeddings_file,\n","             vocab_file = vocab_file,\n","             target_dir = target_dir,\n","             mode = 'char',\n","             max_length=64,\n","             num_labels=3,\n","             epochs=50,\n","             batch_size=256,\n","             lr=0.0005,\n","             patience=3,\n","             max_grad_norm=10.0,\n","             gpu_index=0,\n","             if_save_model=True,\n","             checkpoint=None)\n","  \n","test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n","Metric(test_df.label, test_result.prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTq4viezVqMB"},"source":[""],"execution_count":null,"outputs":[]}]}